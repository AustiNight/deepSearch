# Ralph Tasks

- [/] Epic: Improve Report Quality for Address-Like Topics
  - [x] Define schemas for `PropertyDossier`, `DataGap`, and claim-level citations (field names, types, units, optionality, and source linkage rules)
  - [x] Add provenance fields for retrieval timestamp, source update date, and data currency to support recency weighting
  - [x] Define field-level lineage rules for every `PropertyDossier` field (source precedence, derivation steps, and conflict resolution)
  - [x] Define authority scoring and confidence scoring formulas with explicit numeric scales and weighting rules
  - [x] Define a source taxonomy (authoritative, quasi-official, aggregator, social) with canonical examples and mapping rules
  - [x] Set explicit evidence thresholds as constants (min total sources, min authoritative sources, min authority score) and document them in taxonomy/overseer prompts
  - [x] Define a data currency policy per record type (max acceptable age, recency weighting, and out-of-date handling)
  - [x] Build a jurisdiction availability matrix for primary records (CAD/assessor, tax collector, deed/recorder, zoning/GIS, permits, code enforcement) with explicit “unavailable” semantics
  - [x] Specify data source contracts per record type (endpoint/portal, query inputs, expected fields, rate limits, and parsing rules) and store them in a centralized config
  - [x] Define a ground-truth calibration plan for thresholds/confidence (sample addresses, expected parcel IDs, rubric) and tune scoring against it
  - [x] Implement address normalization rules (USPS abbreviations, directional variants, unit handling) and reuse normalized variants across all queries
  - [x] Implement parcel-resolution workflow: geocode to lat/lon, resolve parcel ID via CAD/assessor lookup, and fall back to GIS parcel-layer spatial join
  - [x] Define deterministic parcel-resolution precedence and tie-break rules (multi-parcel matches, ambiguous address points) and log collisions in `DataGap`
  - [x] Define explicit failure taxonomies for geocode failure, parcel not found, and data unavailable; map each to user-visible messaging and `DataGap`
  - [x] Add dataset discovery for open-data portals (Socrata/DCAT/ArcGIS) and persist dataset metadata (title, source, last updated, license)
  - [x] Implement an evidence-recovery pass when thresholds are not met, prioritizing authoritative property records and GIS layers with retry/backoff, caching, and error taxonomy
  - [x] Define evidence-gating enforcement points in the pipeline (pre-synthesis, post-synthesis, pre-render) and specify fail vs soft-fail behavior
  - [x] Define a hard-fail policy for critical failures (parcel ambiguity unresolved, no authoritative sources, confidence below minimum) with user-visible error reports
  - [x] Define retry/time budgets for evidence recovery (max retries, total time, priority stopping rules)
  - [x] Enforce the primary-records checklist using the availability matrix and block “complete” unless coverage is met or explicitly unavailable
  - [x] Apply source-type scoring (government > quasi-official > aggregator > social) and weight synthesis to prioritize higher-authority sources and recency
  - [x] Map findings into the `PropertyDossier` before rendering and display per-section confidence scores derived from the scoring model
  - [x] Tighten synthesis prompts to require claim-level citations, explicit “Source not found” labels, and a “Data Gaps & Next Steps” section with exact portal/endpoint pointers
  - [x] Improve validation output to human-readable messages that cite the specific missing citations and sections (no “[object Object]”)
  - [x] Add compliance/provenance capture for dataset license/ToS and access constraints and surface them in report metadata
  - [x] Add a compliance enforcement layer for ToS/attribution (block disallowed sources, enforce attribution formatting, and require sign-off gates before rollout)
  - [x] Add privacy/compliance review checks tied to zero-cost mode and portal ToS/license enforcement
  - [x] Add instrumentation for parcel-resolution success, evidence-recovery success, latency, and a measurable confidence-quality proxy metric
  - [x] Define SLO targets for parcel resolution, evidence recovery, and median latency; gate releases when below baseline
  - [ ] Add observability for evidence-gating decisions and portal error taxonomy
  - [ ] Add data privacy posture for address inputs and logs (PII handling and retention)
  - [ ] Add unit/integration tests for address normalization, parcel resolution (multi-parcel, unit-only, rural), evidence gating, and `PropertyDossier` population
  - [ ] Add failure-mode test suite (schema drift, portal 429/503, stale datasets, mixed parcel formats, missing geometry)
  - [ ] Add E2E golden-fixture tests for address reports using frozen datasets
  - [ ] Add migration/backfill plan for cached reports and dataset index when schemas change
  - [ ] Add security review for key storage, logging, and redaction in telemetry
  - [ ] Define performance constraints (max external calls, portal discovery caps, latency budgets) and enforce with guardrails
  - [ ] Acceptance: evidence threshold constants are defined and enforced (with tests that fail/pass around the thresholds), address reports include a populated `PropertyDossier` with required fields when available, primary-record coverage (or explicit unavailability) is shown, confidence tags render for each section, and Data Gaps include exact source pointers

- [ ] Epic: Export Report to PDF
  - [ ] Decide the PDF generation approach and supported browsers before implementation (print-optimized DOM + `window.print` or client-side PDF generator)
  - [ ] Define a PDF spec (page size defaults, margins, font stack, accessibility tags, max file size, filename convention like `deepsearch-report-<topic>-YYYYMMDD.pdf`, and citation/bibliography formatting rules)
  - [ ] Define supported browser/OS test matrix for PDF output and ensure parity targets are explicit
  - [ ] Add an “Export to PDF” button in the report header UI and wire it to the chosen generation method
  - [ ] Create print styles for the report (section/page breaks, table wrapping, image scaling, header/footer)
  - [ ] Ensure output is readable in light/dark modes and pagination is consistent in supported browsers
  - [ ] Add a QA checklist or automated verification for PDF export (layout, tables, citations, headers/footers)
  - [ ] Acceptance: clicking “Export to PDF” downloads a multi-page PDF with intact tables, citations, and bibliography; output matches the defined PDF spec and renders correctly in the supported browser list

- [ ] Epic: Integrate Open Data Portal APIs + Parcel Spatial Joins
  - [ ] Enforce a zero-cost mode: default to public endpoints with no paid services; skip any provider that requires paid access and surface a `DataGap` explaining the skip
  - [ ] Add optional token support (Socrata app token, ArcGIS API key) that increases rate limits but is never required; fall back to anonymous mode when missing
  - [ ] Implement keyless-safe geocoding defaults with strict rate limits and caching (Nominatim or equivalent), and document usage policy requirements in-code and in docs
  - [ ] Add config flags to keep pay-as-you-go disabled and block any paid-tier requests by default
  - [ ] Define a provider interface for open-data portals (discoverDatasets, fetchMetadata, queryByText, queryByGeometry, listFields, getDistributions) and wire a shared response normalization layer
  - [ ] Implement Socrata provider with endpoint contracts: discovery via `/api/search/views?q=...`, metadata via `/api/views/{id}.json`, data via `/resource/{id}.json` with SoQL filters, geometry filters (`within_circle`/`within_polygon`), pagination, and rate limiting
  - [ ] Implement ArcGIS provider with endpoint contracts: discovery via `/sharing/rest/search` (type: “Feature Service” + keywords), item metadata via `/sharing/rest/content/items/{id}`, layer discovery via service `?f=json`, and data queries via `{layerUrl}/query` with geometry + `esriSpatialRelIntersects`, pagination (`resultOffset`/`resultRecordCount`), and `outSR=4326`
  - [ ] Implement DCAT provider: ingest `data.json`/`catalog.json`, filter datasets by keywords and spatial coverage, and use distribution `accessURL`/`downloadURL` to retrieve JSON/CSV where available
  - [ ] Add portal-type detection heuristics (Socrata/ArcGIS/DCAT) from base URL, known endpoints, and metadata signatures
  - [ ] Define authentication handling for providers (API keys, headers, tokens) with secure storage and error surfacing
  - [ ] Build an address-to-geometry service: normalize address, geocode to lat/lon, and persist confidence + normalized variants for downstream queries
  - [ ] Implement address-to-parcel resolution: query parcel datasets by address fields when available; otherwise perform GIS spatial join (point-in-polygon) against parcel layers
  - [ ] Add explicit CRS/reprojection rules for all spatial queries (validate and normalize to EPSG:4326; enforce outSR on queries)
  - [ ] Add a lightweight spatial-join utility (GeoJSON point-in-polygon) and guardrails for large polygon datasets (tiling/bbox filtering, streaming, or server-side query first)
  - [ ] Add dataset usage gates for license/ToS compliance and freshness thresholds, and store “do not use” flags in the dataset index
  - [ ] Add dataset auto‑ingestion: scheduled/triggered crawl of discovered portals to cache dataset metadata, fields, update timestamps, and distributions in a local index
  - [ ] Add feature flags and rollback controls for auto‑ingestion, evidence recovery, and gating enforcement to allow staged rollout
  - [ ] Define nonfunctional budgets (latency per report, max external calls) and align cache TTLs to those budgets
  - [ ] Define dataset index invalidation, TTLs, and re-crawl cadence
  - [ ] Version and validate data source contracts to handle schema changes without breaking queries
  - [ ] Expose auto‑ingested datasets to method discovery and evidence recovery so agents can query by portal type + dataset tags (parcel, zoning, permits, code, 311/911)
  - [ ] Add caching, retry/backoff, and rate-limit policies per provider; surface errors in `DataGap` entries with actionable retry guidance
  - [ ] Add unit/integration tests for each provider (mocked API responses), and spatial-join fixtures for parcel lookups
  - [ ] Acceptance: given a city/county portal URL, the system can discover datasets, query at least one dataset by address or geometry, and populate property-relevant fields with citations; provider tests cover Socrata, ArcGIS, and DCAT flows

- [ ] Epic: Settings UI for Optional Open-Data Keys
  - [ ] Add a Settings UI section that lists optional keys (Socrata app token, ArcGIS API key, optional geocoding key if supported) with clear “not required” language
  - [ ] Explain zero-cost mode defaults and what improves with keys (rate limits, reliability, throughput) without changing core functionality
  - [ ] Link to public setup instructions for each optional key and summarize required fields/format
  - [ ] Add validation messaging that treats missing keys as “OK” and only warns about rate limiting
  - [ ] Add telemetry-free local UI hints that keys are stored securely and never required for baseline operation
  - [ ] Acceptance: Settings UI clearly indicates optional keys are not required, the app functions without them, and adding keys improves scalability only

- [ ] Epic: Transparency Map Scaling + Auto-Updates
  - [ ] Set Transparency Map default scale to 80% (CSS transform or layout scaling) without affecting readability or responsiveness
  - [ ] Ensure the scaled map maintains legible typography and column alignment across mobile/tablet/desktop breakpoints
  - [ ] Implement an auto-update mechanism for the Transparency Map that re-renders whenever taxonomy/blueprint/vertical/method/tactic sources change
  - [ ] Add a single source of truth for Transparency Map data (derived from taxonomy + settings) and recompute on load, settings save, and taxonomy updates
  - [ ] Add a lightweight integrity check to verify the map includes all known verticals/subtopics and flags missing items
  - [ ] Acceptance: Transparency Map renders at 80% scale by default and stays current when new verticals/methods/tactics are added without manual edits

- [ ] Epic: US-Only Address Policy
  - [ ] Add an address-scope classifier that detects non-US inputs (country tokens, postal code formats, or explicit country fields)
  - [ ] Define US-only policy behavior: for non-US addresses, skip US-specific record gates and render a scoped report with `DataGap` entries that explain unsupported jurisdiction
  - [ ] Add a feature flag to enable/disable US-only enforcement and document defaults
  - [ ] Update settings/help text to explain the policy and how non-US inputs are handled
  - [ ] Add tests for US vs non-US address inputs (UK, CA, EU formats) and verify correct policy behavior
  - [ ] Acceptance: non-US address inputs are explicitly flagged as out-of-scope with clear guidance, and US-only record gates are not applied

## Dependency Order

- Define schemas (`PropertyDossier`, `DataGap`, citations) and provenance fields
- Define source taxonomy, scoring formulas, evidence thresholds, and data currency policy
- Build jurisdiction availability matrix and data source contracts
- Implement address normalization, geocoding, and parcel resolution (with CRS rules)
- Implement provider integrations and dataset index (discovery, ingestion, licensing gates)
- Add evidence recovery, gating enforcement, and hard-fail policy
- Update synthesis/validation/report rendering
- Add observability, SLOs, and test suites
- Add UI updates (Settings optional keys, Transparency Map scaling)
